rl\_hybrid\_attitude/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ run\_scripts/
‚îÇ ‚îú‚îÄ‚îÄ collect\_expert.sh
‚îÇ ‚îú‚îÄ‚îÄ bc\_pretrain.sh
‚îÇ ‚îú‚îÄ‚îÄ rl\_train.sh
‚îÇ ‚îî‚îÄ‚îÄ evaluate.sh
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ envs/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ attitude\_env.py
‚îÇ ‚îú‚îÄ‚îÄ expert/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ expert\_pid.py
‚îÇ ‚îú‚îÄ‚îÄ imitation/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ behavioral\_cloning.py
‚îÇ ‚îú‚îÄ‚îÄ rl/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ train\_rl.py
‚îÇ ‚îú‚îÄ‚îÄ utils/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ replay\_buffer.py
‚îÇ ‚îî‚îÄ‚îÄ evaluate/
‚îÇ ‚îî‚îÄ‚îÄ evaluate\_policy.py
‚îî‚îÄ‚îÄ outputs/
‚îú‚îÄ‚îÄ expert\_data.npz
‚îú‚îÄ‚îÄ bc\_policy.pth
‚îî‚îÄ‚îÄ rl\_model.zip

‚úÖ 1. Open Command Prompt and go to your project
cd C:\\Users\\shrid\\Desktop\\Projects\\rl\_hybrid\_attitude

‚úÖ 2. Activate your virtual environment
..venv\\Scripts\\activate

You should now see:
(.venv) C:\\Users\\shrid\\Desktop\\Projects\\rl\_hybrid\_attitude>

‚úÖ 3. (Optional) Verify that all required packages are installed
python -c "import gymnasium, stable\_baselines3, torch, numpy; print('All good.')"

üöÄ 4. Run Expert Demonstration Collection
This will create outputs/expert\_data.npz.
python -m src.collect\_expert --episodes 120 --out outputs/expert\_data.npz

üß† 5. Run Behavioral Cloning (Supervised Imitation Learning)
This trains the imitation (BC) policy and saves:

outputs/bc\_policy.pth

Run:
python -m src.imitation.behavioral\_cloning --data outputs/expert\_data.npz --save outputs/bc\_policy.pth --epochs 100

ü§ñ 6. Run PPO Reinforcement Learning (Fine-tuning on top of BC policy)
This will train PPO and save:

outputs/rl\_model.zip

Command:
python -m src.rl.train\_rl --timesteps 200000 --bc outputs/bc\_policy.pth --out outputs/rl\_model.zip

Use lower timesteps for testing:
python -m src.rl.train\_rl --timesteps 50000 --bc outputs/bc\_policy.pth --out outputs/rl\_model.zip

üìä 7. Evaluate the final RL policy
Runs evaluation episodes and prints mean reward:
python -m src.evaluate.evaluate\_policy --model outputs/rl\_model.zip --episodes 50

üéâ 8. (Optional) Deactivate virtual environment
deactivate

üëç FINAL SUMMARY (Copy‚ÄìPaste Ready)
cd C:\\Users\\shrid\\Desktop\\Projects\\rl\_hybrid\_attitude
..venv\\Scripts\\activate

python -m src.collect\_expert --episodes 120 --out outputs/expert\_data.npz
python -m src.imitation.behavioral\_cloning --data outputs/expert\_data.npz --save outputs/bc\_policy.pth --epochs 100
python -m src.rl.train\_rl --timesteps 200000 --bc outputs/bc\_policy.pth --out outputs/rl\_model.zip
python -m src.evaluate.evaluate\_policy --model outputs/rl\_model.zip --episodes 50

Want one command to run everything (full pipeline)?
I can generate a run\_all.bat file that:

activates venv

collects expert data

runs BC

runs PPO

evaluates

saves logs

Just say ‚ÄúCreate run\_all.bat‚Äù.

Extra: evaluating the BC (behavioral cloning) model

If you want to evaluate your saved BC PyTorch bc\_policy.pth (not the SB3 model), here's a tiny snippet you can add to src/evaluate/evaluate\_policy.py or run separately.

# quick BC eval (only if BCNet class is available in src.imitation.behavioral\_cloning)

import torch
from src.imitation.behavioral\_cloning import BCNet

def eval\*bc(bc\_path, episodes=50):
env = AttitudeDetumbleEnv()
model = BCNet()
model.load\_state\_dict(torch.load(bc\_path, map\_location="cpu"))
model.eval()
rewards = \[]
for \* in range(episodes):
obs, \_ = env.reset()
done = False
ep\_ret = 0.0
while not done:
with torch.no\_grad():
a = model(torch.from\_numpy(obs.astype(np.float32)).unsqueeze(0)).squeeze(0).numpy()
next\_obs, reward, terminated, truncated, info = env.step(a)
done = bool(terminated or truncated)
obs = next\_obs
ep\_ret += float(reward)
rewards.append(ep\_ret)
print("BC mean return:", float(np.mean(rewards)))

.\.venv\\Scripts\\activate
run_all.bat

